{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of assignment aims to provide you with some exposure to the use of autoencoders. Use\n",
    "the full MNIST dataset for this problem.\n",
    "Hints: Use corruption level = 0.1, training epochs = up to about 25, learning rate = 0.1, and batch\n",
    "size = 128 for training of all the layers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For an easier implementation we would like to implement most of the function in the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "\n",
    "\n",
    "def init_weights(n_in, n_out, name_weight):\n",
    "    weight = np.asarray(\n",
    "        np.random.uniform(\n",
    "            low=-4 * np.sqrt(6. / (n_in + n_out)),\n",
    "            high=4 * np.sqrt(6. / (n_in + n_out)),\n",
    "            size=(n_in, n_out)),\n",
    "        dtype=theano.config.floatX)\n",
    "    return theano.shared(value=weight, name=name_weight, borrow=True)\n",
    "\n",
    "\n",
    "def init_bias(n, name_bias):\n",
    "    return theano.shared(value=np.zeros(n, dtype=theano.config.floatX), name=name_bias, borrow=True)\n",
    "\n",
    "\n",
    "def init_weight_biases_4dimension(filter_shape, d_type):\n",
    "    fan_in = np.prod(filter_shape[1:])\n",
    "    fan_out = filter_shape[0] * np.prod(filter_shape[2:])\n",
    "\n",
    "    bound = np.sqrt(6. / (fan_in + fan_out))\n",
    "    w_values = np.asarray(\n",
    "        np.random.uniform(low=-bound, high=bound, size=filter_shape),\n",
    "        dtype=d_type)\n",
    "    b_values = np.zeros((filter_shape[0],), dtype=d_type)\n",
    "    return theano.shared(w_values, borrow=True), theano.shared(b_values, borrow=True)\n",
    "\n",
    "\n",
    "def init_weight_biases_2dimensions(filter_shape, d_type):\n",
    "    fan_in = filter_shape[1]\n",
    "    fan_out = filter_shape[0]\n",
    "\n",
    "    bound = np.sqrt(6. / (fan_in + fan_out))\n",
    "    w_values = np.asarray(\n",
    "        np.random.uniform(low=-bound, high=bound, size=filter_shape),\n",
    "        dtype=d_type)\n",
    "    b_values = np.zeros((filter_shape[1],), dtype=d_type)\n",
    "    return theano.shared(w_values, borrow=True), theano.shared(b_values, borrow=True)\n",
    "\n",
    "\n",
    "def shuffle_data(samples, labels):\n",
    "    idx = np.arange(samples.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    samples, labels = samples[idx], labels[idx]\n",
    "    return samples, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxAutoEncoder:\n",
    "    def __init__(self, num_features, num_outputs, list_hidden_layer, learning_rate,\n",
    "                 corruption_level=0.01,\n",
    "                 sparsity_parameter=0.01, penalty_parameter=0.01):\n",
    "\n",
    "        \"\"\"\n",
    "        :param list_hidden_layer: [10, 20] -> means 2 hidden layer, 10 neurons ->layer_1, 10 neurons -> layer_2\n",
    "        :param corruption_level: made the noise in the data\n",
    "        :param learning_rate: learning rate\n",
    "        :param sparsity_parameter: 0.1 -> means 0.1 of neurons is activated\n",
    "        :param penalty_parameter: learning decay\n",
    "        \"\"\"\n",
    "\n",
    "        list_neurons = [num_features] + list_hidden_layer\n",
    "        x = T.matrix('x')\n",
    "        d = T.matrix('d')\n",
    "\n",
    "        self.total_costs_auto_encoder = []\n",
    "        self.total_costs_full = []\n",
    "        self.total_predictions_full = []\n",
    "\n",
    "        \"\"\"\n",
    "            Do the data corruption\n",
    "        \"\"\"\n",
    "\n",
    "        x = self.corrupt_the_data(corruption_level=corruption_level, x=x)\n",
    "\n",
    "        \"\"\"\n",
    "            Construct the auto encoder\n",
    "        \"\"\"\n",
    "\n",
    "        weights = []\n",
    "        biases = []\n",
    "\n",
    "        prev_output = x\n",
    "\n",
    "        \"\"\"\n",
    "            ENCODER\n",
    "        \"\"\"\n",
    "\n",
    "        for i in range(1, len(list_neurons)):\n",
    "\n",
    "            weight = init_weights(list_neurons[i-1], list_neurons[i], 'weight_%s' % i)\n",
    "            bias = init_bias(list_neurons[i], 'bias_%s' % i)\n",
    "\n",
    "            weights.append(weight)\n",
    "            biases.append(bias)\n",
    "\n",
    "            prev_output = T.nnet.sigmoid(T.dot(prev_output, weight) + bias)\n",
    "\n",
    "        \"\"\"\n",
    "            DECODER\n",
    "        \"\"\"\n",
    "\n",
    "        buffer_output = prev_output\n",
    "        biases_trans = []\n",
    "\n",
    "        for i in range(len(weights)-1, -1, -1):\n",
    "\n",
    "            weight_transpose = weights[i].transpose()\n",
    "            bias_transpose = init_bias(list_neurons[i], 'bias_trans_%s' % i)\n",
    "\n",
    "            biases_trans.append(bias_transpose)\n",
    "\n",
    "            prev_output = T.nnet.sigmoid(T.dot(prev_output, weight_transpose) + bias_transpose)\n",
    "\n",
    "        cost = - T.mean(T.sum(x * T.log(prev_output) + (1 - x) * T.log(1 - prev_output), axis=1))\n",
    "\n",
    "        params = weights+biases+biases_trans\n",
    "        grads = T.grad(cost, params)\n",
    "        updates = [(param, param - learning_rate*grad) for param, grad in zip(params, grads)]\n",
    "\n",
    "        self.train_encoder = theano.function(\n",
    "            inputs=[x],\n",
    "            updates=updates,\n",
    "            outputs=[prev_output, cost]\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "            TRAIN THE FULL CONNECTED LAYER\n",
    "        \"\"\"\n",
    "\n",
    "        last_weight = init_weights(list_neurons[-1], num_outputs, 'last_weight')\n",
    "        last_bias = init_bias(num_outputs, 'last_bias')\n",
    "\n",
    "        buffer_output = T.nnet.softmax(T.dot(buffer_output, last_weight) + last_bias)\n",
    "        y_pred = T.argmax(buffer_output, axis=1)\n",
    "\n",
    "        cost_cross = T.mean(T.nnet.categorical_crossentropy(buffer_output, d))\n",
    "\n",
    "        params_full = weights + [last_weight] + biases + [last_bias]\n",
    "        grads_full = T.grad(cost_cross, params_full)\n",
    "        updates_full = [(param, param - learning_rate * grad) for param, grad in zip(params_full, grads_full)]\n",
    "\n",
    "        self.train_cross = theano.function(\n",
    "            inputs=[x, d],\n",
    "            updates=updates_full,\n",
    "            outputs=[prev_output, y_pred, cost_cross]\n",
    "        )\n",
    "\n",
    "        self.test_cross = theano.function(\n",
    "            inputs=[x],\n",
    "            outputs=[y_pred]\n",
    "        )\n",
    "\n",
    "    def corrupt_the_data(self, corruption_level, x):\n",
    "\n",
    "        # use binomial dist at corrupt the data\n",
    "        rng = np.random.RandomState(123)\n",
    "        theano_rng = RandomStreams(rng.randint(2 ** 30))\n",
    "\n",
    "        tilde_x = theano_rng.binomial(size=x.shape, n=1, p=1 - corruption_level,\n",
    "                                      dtype=theano.config.floatX) * x\n",
    "\n",
    "        return tilde_x\n",
    "\n",
    "    def start_train_auto_encoder(self, epochs, batch_size, train_x, train_y, verbose=False):\n",
    "\n",
    "        print \"Start training the auto encoder\"\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # go through trainng set\n",
    "\n",
    "            costs = []\n",
    "            results = []\n",
    "\n",
    "            for start, end in zip(range(0, len(train_x), batch_size), range(batch_size, len(train_y), batch_size)):\n",
    "                result, cost = self.train_encoder(train_x[start:end])\n",
    "                costs.append(cost)\n",
    "                results.append(result)\n",
    "\n",
    "            self.total_costs_auto_encoder.append(np.mean(costs, dtype='float64'))\n",
    "\n",
    "            if verbose:\n",
    "                print \"Epoch: %d Cost: %s \\n\" % (epoch, self.total_costs_auto_encoder[epoch])\n",
    "\n",
    "    def start_train_the_full(self, epochs, batch_size, train_x, train_y, test_x, test_y):\n",
    "\n",
    "        print \"Start training the full hidden layer with autoencoder\"\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # go through trainng set\n",
    "            costs = []\n",
    "            results = []\n",
    "\n",
    "            for start, end in zip(range(0, len(train_x), batch_size), range(batch_size, len(train_y), batch_size)):\n",
    "                output, result, cost = self.train_cross(train_x[start:end], train_y[start:end])\n",
    "                costs.append(cost)\n",
    "                results.append(np.mean(np.argmax(test_y, axis=1) == self.test_cross(test_x)))\n",
    "\n",
    "            self.total_costs_full.append(np.mean(costs, dtype='float64'))\n",
    "            self.total_predictions_full.append(np.mean(results, dtype='float64'))\n",
    "            print \"result: %s, cost: %s \\n\" % (self.total_costs_full[epoch], self.total_predictions_full[epoch])\n",
    "\n",
    "    def get_total_costs_of_auto_encoder(self):\n",
    "\n",
    "        return self.total_costs_auto_encoder\n",
    "\n",
    "    def get_total_cost_and_prediction_full(self):\n",
    "\n",
    "        return self.total_costs_full, self.total_predictions_full\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collections class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cPickle\n",
    "\n",
    "class DataCollector:\n",
    "\n",
    "    def __init__(self, file_path):\n",
    "\n",
    "        with open(file_path, \"rb\") as input_file:\n",
    "            self.data = cPickle.load(input_file)\n",
    "\n",
    "        self.data_train = self.data[0]\n",
    "        self.data_test = self.data[2]\n",
    "        self.data_validate = self.data[1]\n",
    "\n",
    "    def get_train_data(self):\n",
    "\n",
    "        return self.data_train[0], self.return_one_hot_encoding(10, self.data_train[1])\n",
    "\n",
    "    def get_test_data(self):\n",
    "\n",
    "        return self.data_test[0], self.return_one_hot_encoding(10, self.data_test[1])\n",
    "\n",
    "    def get_validation_data(self):\n",
    "\n",
    "        return self.data_validate[0], self.return_one_hot_encoding(10, self.data_validate[1])\n",
    "\n",
    "    def return_one_hot_encoding(self, num_output, list_data):\n",
    "\n",
    "        zeros = np.zeros((len(list_data), num_output))\n",
    "\n",
    "        for i in range(len(zeros)):\n",
    "\n",
    "            zeros[i][list_data[i]] = 1\n",
    "\n",
    "        return zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class DataVisualization:\n",
    "\n",
    "   def __init__(self):\n",
    "       return\n",
    "\n",
    "   def show_plot(self, list_x_point, list_y_point, x_label, y_label, title, figure_name):\n",
    "       plt.figure()\n",
    "       plt.plot(list_x_point, list_y_point)\n",
    "       plt.xlabel(x_label)\n",
    "       plt.ylabel(y_label)\n",
    "       plt.title(title)\n",
    "       plt.savefig(figure_name)\n",
    "       plt.show()\n",
    "\n",
    "\n",
    "class DataVisualizationWithLabels:\n",
    "   def __init__(self):\n",
    "       return\n",
    "\n",
    "   def show_plot(self, list_x_point, list_y_point, x_label, y_label, title, figure_name, labels):\n",
    "       plt.figure()\n",
    "\n",
    "       for cnt in range(len(labels)):\n",
    "           plt.plot(list_x_point[cnt], list_y_point[cnt], label=labels[cnt])\n",
    "\n",
    "       plt.xlabel(x_label)\n",
    "       plt.ylabel(y_label)\n",
    "       plt.title(title)\n",
    "       plt.legend()\n",
    "       plt.savefig(figure_name)\n",
    "       plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collector = DataCollector(\"../mnist.pkl\")\n",
    "data_visualize = DataVisualizationWithLabels()\n",
    "\n",
    "train_x, train_y = data_collector.get_train_data()\n",
    "test_x, test_y = data_collector.get_test_data()\n",
    "validate_x, validate_y = data_collector.get_validation_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Design a stacked denoising autoencoder consisting of three hidden-layers; 900 neurons in the\n",
    "first hidden-layer, 625 neurons in the second hidden-layer, and 400 neurons in the third\n",
    "hidden-layer. To train the network:\n",
    "- Use the training dataset of MNIST digits\n",
    "- Corrupt the input data using a binomial distribution at 10% corruption level.\n",
    "- Use cross-entropy as the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the auto encoder\n",
      "Epoch: 0 Cost: 544.641947474 \n",
      "\n",
      "Epoch: 1 Cost: 515.683312469 \n",
      "\n",
      "Epoch: 2 Cost: 488.508844992 \n",
      "\n",
      "Epoch: 3 Cost: 453.991500725 \n",
      "\n",
      "Epoch: 4 Cost: 418.858746211 \n",
      "\n",
      "Epoch: 5 Cost: 387.687735663 \n",
      "\n",
      "Epoch: 6 Cost: 361.267816145 \n",
      "\n",
      "Epoch: 7 Cost: 339.445162811 \n",
      "\n",
      "Epoch: 8 Cost: 321.808586054 \n",
      "\n",
      "Epoch: 9 Cost: 307.6935674 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112793190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_feature = len(train_x[0])\n",
    "epochs = 10\n",
    "batch_size = 20000\n",
    "file_save = './images/1_cost.png'\n",
    "\n",
    "softmax = SoftmaxAutoEncoder(num_features=num_feature, num_outputs=10,\n",
    "                             list_hidden_layer=[10], learning_rate=0.05,\n",
    "                            corruption_level=0.1)\n",
    "\n",
    "softmax.start_train_auto_encoder(epochs=epochs, batch_size=batch_size, train_x=train_x, \n",
    "                                 train_y=train_y, verbose=True)\n",
    "\n",
    "total_costs_auto_encoder = softmax.get_total_costs_of_auto_encoder()\n",
    "\n",
    "len(total_costs_auto_encoder)\n",
    "data_visualize.show_plot(\n",
    "    list_y_point=[total_costs_auto_encoder], \n",
    "    list_x_point=[range(epochs)],\n",
    "    x_label='epochs',\n",
    "    y_label='costs',\n",
    "    title='cross entropy costs',\n",
    "    figure_name=file_save,\n",
    "    labels=['cost']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
